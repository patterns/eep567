{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15551,"status":"ok","timestamp":1742090209237,"user":{"displayName":"Hsin-ih “興怡” Tu","userId":"08845434978895628909"},"user_tz":420},"id":"3wvh7u8RHZ33","outputId":"64630e71-f7a4-472c-a83d-c0d772964143"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loading VPN 60s (ftm) ds.\n","Train set size: 5548\n","Test set size: 1387\n","              precision    recall  f1-score   support\n","\n","           0       0.77      0.82      0.80       513\n","           1       0.33      0.28      0.30       104\n","           2       0.53      0.45      0.49       190\n","           3       0.68      0.65      0.66        71\n","           4       0.73      0.74      0.73       151\n","           5       0.56      0.65      0.60        34\n","           6       0.87      0.90      0.88       324\n","\n","    accuracy                           0.73      1387\n","   macro avg       0.64      0.64      0.64      1387\n","weighted avg       0.72      0.73      0.72      1387\n","\n","KNN F1: 0.7458656152835103\n","KNN precision: 0.7879925162988884\n","KNN recall: 0.7146233833289954\n","KNN report:\n","               precision    recall  f1-score   support\n","\n","           0       0.77      0.83      0.80       513\n","           1       0.63      0.26      0.37       104\n","           2       0.74      0.37      0.50       190\n","           3       0.67      0.55      0.60        71\n","           4       0.69      0.66      0.68       151\n","           5       0.76      0.56      0.64        34\n","           6       0.89      0.86      0.87       324\n","\n","   micro avg       0.78      0.69      0.73      1387\n","   macro avg       0.74      0.59      0.64      1387\n","weighted avg       0.77      0.69      0.72      1387\n"," samples avg       0.78      0.69      0.69      1387\n","\n"]}],"source":["\"\"\"\n","\n","# Note, in Colab that we use the UI to mount G-drive\n","\n","\"\"\"\n","\n","import os\n","from pathlib import Path\n","\n","print(\"Loading VPN 60s (ftm) ds.\")\n","data_dir60 = Path(os.path.abspath(\"/content/drive/MyDrive/eep567/TimeBasedFeatures-Dataset-60s-VPN.arff\"))\n","\n","import pandas as pd\n","df = pd.read_csv(data_dir60)\n","####df.head()\n","####df.info()\n","####df[\"Unnamed: 23\"].value_counts()\n","####df.describe() #(shows max of 1000000 and min of 0 in Unnamed: 9; large variance in values)\n","proj_random_seed = 42\n","recursion_depth = df.shape[1] // 2    #(experimental depth as half of # columns)\n","\n","# derive feature / label subgroups from pool\n","# (skip the top 26 rows which are NaN)\n","# the \"Unnamed: 23\" column contains the network traffic category\n","features_pool = df.drop([\"Unnamed: 23\"], axis=1).values[26:]\n","category_pool = df[\"Unnamed: 23\"].values[26:]\n","from sklearn.model_selection import train_test_split\n","train_set, test_set, train_category, test_category = train_test_split(\n","    features_pool, category_pool, test_size=0.2, random_state=proj_random_seed\n",")\n","print(\"Train set size:\", len(train_category))\n","print(\"Test set size:\", len(test_category))\n","\n","# for decision trees, scaling is unnecessary. only use scaling with PCA\n","from sklearn.decomposition import PCA\n","from sklearn.pipeline import make_pipeline\n","from sklearn.preprocessing import StandardScaler\n","pca_pipeline = make_pipeline(StandardScaler(), PCA())\n","features_std_scaled = pca_pipeline.fit_transform(train_set)\n","\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.preprocessing import OneHotEncoder\n","\n","ohenc = OneHotEncoder(handle_unknown='ignore')\n","many_observations_of_one_feature = train_category.reshape(-1,1)\n","fitted_categories = ohenc.fit(many_observations_of_one_feature)\n","# ~ print(fitted_categories.categories_)\n","# ~ print(many_observations_of_one_feature[:10])\n","\n","labels_train = ohenc.transform(many_observations_of_one_feature).toarray()\n","# regularize with max_depth\n","dtc_model = DecisionTreeClassifier(max_depth=recursion_depth, random_state=proj_random_seed)\n","dtc_model.fit(features_std_scaled, labels_train)\n","\n","# to inspect the tree (as plain text)\n","from sklearn import tree\n","tree_format_text = tree.export_text(dtc_model)\n","# ~ print(tree_format_text)\n","# to inspect the tree (as graphvis diagram)\n","# ~ category_columns = ohenc.get_feature_names_out()\n","# ~ tree.export_graphviz(\n","\t# ~ dtc_model,\n","\t# ~ out_file=\"timeout60_tree.dot\",\n","\t# ~ class_names=category_columns,\n","\t# ~ rounded=True,\n","\t# ~ filled=True\n","# ~ )\n","# ~ from graphviz import Source\n","# ~ Source.from_file(\"timeout60_tree.dot\")\n","\n","\n","# ~ from sklearn.model_selection import cross_val_score\n","# ~ measure_performance = cross_val_score(dtc_model, features_std_scaled, labels_train , cv=10)\n","# ~ pd.Series(measure_performance).describe()\n","from sklearn.model_selection import cross_val_predict\n","# ~ labels_predict = cross_val_predict(dtc_model, features_std_scaled, labels_train , cv=10)\n","# ~ decode_predict = labels_predict.argmax(axis=1)\n","# ~ decode_train = labels_train.argmax(axis=1)\n","# ~ from sklearn.metrics import confusion_matrix\n","# ~ cm = confusion_matrix(decode_train, decode_predict)\n","# ~ print(cm)\n","# ~ from sklearn.metrics import precision_score, recall_score\n","# ~ pr_score = precision_score(decode_train, decode_predict, average='weighted')\n","# ~ rc_score = recall_score(decode_train, decode_predict, average='weighted')\n","# ~ print(pr_score)\n","# ~ print(rc_score)\n","# ~ from sklearn.metrics import f1_score\n","# ~ combo_score = f1_score(decode_train, decode_predict, average='weighted')\n","# ~ print(combo_score)\n","\n","n_observations_test_category = test_category.reshape(-1,1)\n","labels_test = ohenc.transform(n_observations_test_category).toarray()\n","features_scaled_test = pca_pipeline.fit_transform(test_set)\n","\n","labels_predict_test = cross_val_predict(dtc_model, features_scaled_test, labels_test , cv=10)\n","decode_predict_test = labels_predict_test.argmax(axis=1)\n","decode_test = labels_test.argmax(axis=1)\n","from sklearn.metrics import classification_report\n","classifi_rpt = classification_report(decode_test, decode_predict_test)\n","print(classifi_rpt)\n","\n","\n","# nearest neighbor algo\n","from sklearn.neighbors import KNeighborsClassifier\n","knn_clf = KNeighborsClassifier()\n","knn_clf.fit(features_std_scaled, labels_train)\n","knn_train_predict = cross_val_predict(knn_clf, features_std_scaled, labels_train , cv=10)\n","from sklearn.metrics import f1_score\n","# macro means all labels are equally important (versus weighted)\n","knn_f1_score = f1_score(labels_train, knn_train_predict, average='macro')\n","print(\"KNN F1:\", knn_f1_score)\n","from sklearn.metrics import precision_score, recall_score\n","knn_pr_score = precision_score(labels_train, knn_train_predict, average='macro')\n","knn_rc_score = recall_score(labels_train, knn_train_predict, average='macro')\n","print(\"KNN precision:\", knn_pr_score)\n","print(\"KNN recall:\", knn_rc_score)\n","import numpy as np\n","# we are specifying np.nan in the report to address the warning of unpredicted labels\n","knn_validat_predict = cross_val_predict(knn_clf, features_scaled_test, labels_test , cv=10)\n","# ~ knn_classifi_rpt = classification_report(labels_test, knn_validat_predict)\n","knn_classifi_rpt = classification_report(labels_test, knn_validat_predict, zero_division=np.nan)\n","print(\"KNN report:\\n\", knn_classifi_rpt)\n"]}],"metadata":{"colab":{"provenance":[{"file_id":"1gm4ecQuuyAxr-z-hX_jOSp6ZGBmyLpq1","timestamp":1742080525423},{"file_id":"1_qrYahOhqpsoOpt7po6TBSGyUNuyUaxw","timestamp":1741907427826}],"mount_file_id":"1AupDWI70d_4RYIvLMwa9bW_tNhoQhbPr","authorship_tag":"ABX9TyMrrQvpsYgteCU19FodD4M3"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}